## 如何跟踪slab大小

beegfs获取元数据 有2个方式（基本上只2个路线）
1. 通过rpc查询 一次基本sockt通讯过程

2. 注册到内核 形成新文件类型Fhgf文件 然后用户执行标准读写操作。

多次gdb跟踪发现内存会出现变化地方

ModeMigrate::testFile
MigrateFile::copyData
App::initDataObjects()

可能引起内存增长位置：
代码1 ModeMigrate::testFile--> ModeMigrate::getEntryTargets--->MessagingTk::requestResponse--->NETMSGTYPE_GetEntryInfoResp-->
   NodeConnPool* connPool = node.getConnPool()--   Socket* socket;
 原因：node.getConnPool() 每次是否一样 从哪里来的？ 看 代码3 
 

代码2. MigrateFile::migrateRegularFile() -->MigrateFile::copyData---read--

代码3 程序连接rdma地方 就是1的后面 

App::run()--->App::runNormal()--->App::initDataObjects()--->initLocalNodeInfo--->useRDMA（配置文件）


一次rpc过程 RPC
NETMSGTYPE_GetEntryInfoResp-->MessagingTk::requestResponseComm--->node.getConnPool();

find /mnt/beegfs/1w_128k -type f |xargs -n1 -P 3    beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 


find /mnt/beegfs/1w_128k -type f | beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1  -



beegfs-ctl  --getentryinfo /mnt/beegfs/test/2 --verbose

Entry type: file
EntryID: 0-638EFB9F-3
Metadata node: h12-meta01 [ID: 3]
Stripe pattern details:
+ Type: RAID0
+ Chunksize: 512K
+ Number of storage targets: desired: 4; actual: 1
+ Storage targets:
  + 101 @ h12-meta01 [ID: 400]
Chunk path: u0/638E/F/0-638EFA25-3/0-638EFB9F-3
Dentry path: 53/2/0-638EFA25-3/

beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  /mnt/beegfs/test/2

ps -ef |grep beegfs-ctl |awk '{print $2}'



[root@h12-meta01 test]#  beegfs-ctl  --getentryinfo /mnt/beegfs/test/2 --verbose
Entry type: file
EntryID: 0-638EFBDE-3
Metadata node: h12-meta01 [ID: 3]
Stripe pattern details:
+ Type: RAID0
+ Chunksize: 512K
+ Number of storage targets: desired: 4; actual: 1
+ Storage targets:
  + 102 @ h12-meta01 [ID: 400]
Chunk path: u0/638E/F/0-638EFA25-3/0-638EFBDE-3
Dentry path: 53/2/0-638EFA25-3/



[root@localhost test]#  beegfs-ctl  --getentryinfo /mnt/beegfs/test/1 --verbose
Entry type: file
EntryID: 4-638EFA25-3
Metadata node: h12-meta01 [ID: 3]
Stripe pattern details:
+ Type: RAID0
+ Chunksize: 512K
+ Number of storage targets: desired: 4; actual: 1
+ Storage targets:
  + 101 @ h12-meta01 [ID: 400]
Chunk path: u0/638E/F/0-638EFA25-3/4-638EFA25-3
Dentry path: 53/2/0-638EFA25-3/

find /mnt/beegfs/test -type f | beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  -

beegfs-ctl  --getentryinfo /mnt/beegfs/test/1 --verbose
Entry type: file
EntryID: 0-ss-3
Metadata node: h12-meta01 [ID: 3]
Stripe pattern details:
+ Type: RAID0
+ Chunksize: 512K
+ Number of storage targets: desired: 4; actual: 1
+ Storage targets:
  + 102 @ h12-meta01 [ID: 400]
Chunk path: u0/638E/F/0-638EFA25-3/0-638EFB21-3
Dentry path: 53/2/0-638EFA25-3/




find /mnt/beegfs/test -type f | beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  -
 
find /mnt/beegfs/10G/ -type f | beegfs-ctl --getentryinfo -

find /mnt/beegfs/1w_128k -type f | beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  -

find /mnt/beegfs/1w_128k -type f | beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1  -


find /mnt/beegfs/test -type f | beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  -

find /mnt/beegfs/test -type f | beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1  -


2022-12-06 16:14:12
task_struct 700.004



 
find /mnt/beegfs/1w_128k -type f | beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 


/diluv2/tools/vdbench50406/vdbench -f /diluv2/tools/vdbench50406/examples/filesys/create_files
find /mnt/beegfs/10G/ -type f |xargs -n1  -P1 beegfs-ctl --getentryinfo -


find /mnt/beegfs/1w_128k -type f | beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 
find /mnt/beegfs/ -type f |xargs -n1  -P1 beegfs-ctl --getentryinfo -

task_struct 183.834
2022-12-06 14:19:16


代码行数统计：
分级存储 4352行
冷热数据迁移：5,853

make package-rpm PACKAGE_DIR=/root/beegfs/packages21  RPMBUILD_OPTS="-D 'MAKE_CONCURRENCY 20'"
s

解决思路

1 testFile 功能
 a. 区分文件在块池 还是慢池  --getentryinfo 已经判断
 b. 返回isBuddyMirrored  numTargets 后面迁移使用【后面看代码具体差异】
 
2 对比一下tcp为不造成内存增长，在获取元数据上和rdma区别

3. 为啥单个文件迁移不造成增长，多个造成内存增长 分配器策略是什么

3. 源码make对比一下



 find /mnt/beegfs/1w_128k/ -type f |xargs -n1  -P1  -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 {}"


 find /mnt/beegfs/1w_128k -type f |xargs -n1    beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 
 



find /mnt/beegfs/ -type f |xargs -n1  -P1  -I{} sh -c " sleep 1 && beegfs-ctl --getentryinfo {}"

find /mnt/beegfs/1w_128k -type f |xargs -n1    beegfs-ctl --getentryinfo


beegfs-ctl --getentryinfo --verbose /mnt/beegfs/jstack.txt


find /mnt/beegfs/ -type f |xargs -n1  -P 3 beegfs-ctl --getentryinfo

2022-12-05 17:03:08
task_struct 40.7666

2022-12-05 17:03:23
task_struct 41.0916

2022-12-05 17:03:37
task_struct 41.5938

2022-12-05 17:03:57
task_struct 42.1255

2022-12-05 17:05:01
task_struct 42.1255

2022-12-05 17:06:09
task_struct 42.5686

2022-12-05 17:07:34
task_struct 42.5686


2022-12-05 17:10:17
task_struct 42.5686


find /mnt/beegfs/10G/ -type f |xargs -n1  -P1 beegfs-ctl --getentryinfo
find /mnt/beegfs/10G/ -type f |xargs -n1  -P1 beegfs-ctl --getentryinfo


find /mnt/beegfs/10G/ -type f |xargs -n1  -P1 beegfs-ctl --getentryinfo -

find /mnt/beegfs/10G/ -type f |  beegfs-ctl --getentryinfo -
2022-12-05 16:58:07
task_struct 40.2349


/diluv2/tools/vdbench50406/vdbench -f /diluv2/tools/vdbench50406/examples/filesys/create_files
find /mnt/beegfs/1w_128k -type f |xargs -n1    beegfs-ctl --getentryinfo

beegfs-ctl --getentryinfo

for i in {1..50}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=10G; done

find /mnt/beegfs/10G/ -type f |xargs -n1  -P1  -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 {}"



beegfs-ctl --migrate --storagepoolid=1 --destinationpoolid=2 /mnt/beegfs/10G


for i in {1..50}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=10G; done


for i in {1..50}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=1G; done
find /mnt/beegfs/1G/ -type f |xargs -n1  -P3  -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 {}"



for i in {1..500}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=128k; done
find /mnt/beegfs/128k/ -type f |xargs -n1   -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  {}"

 
for i in {1..50}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=10G; done
ps -ef |grep beegfs-ctl |awk '{print $2}' |xargs -n1 kill -9


find /mnt/beegfs/1/ -type f |xargs -n1   -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2  {}"

netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'


beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 /mnt/beegfs/100G/11G.file

beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 /mnt/beegfs/100G/1G.file


find /mnt/beegfs/1G/ -type f |xargs -n1   -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 {}"

beegfs-ctl  --migrate   --storagepoolid=1 --destinationpoolid=2 /mnt/beegfs/1G/10G.file

beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 /mnt/beegfs/1G/10G.file

/diluv2/tools/vdbench50406/vdbench -f /diluv2/tools/vdbench50406/examples/filesys/create_files

dd if=/dev/zero of=1G.file bs=1 count=0 seek=1G
beegfs-ctl --migrate --storagepoolid=2 --destinationpoolid=3 /mnt/beegfs/1G.file

for i in {1..50}; do  dd if=/dev/zero of=${i}G.file bs=1 count=0 seek=1G; done
for i in {1..50}; do  echo ${i}G.file; done

in i in {1..100}
do
	if=/dev/zero of=$i.file bs=1 count=0 seek=50G;
done

echo 3 > /proc/sys/vm/drop_caches


checkFileStripes

UInt16List searchStorageTargetIDs; // storage targets we are looking for and to migrate from
UInt16Vector destStorageTargetIDs; // storage targets we will migrate data to


## 创建文件
dd if=/dev/zero of=1G.file bs=1 count=0 seek=1G
beegfs-ctl --migrate --storagepoolid=1 --destinationpoolid=2 /mnt/beegfs/1G.file
beegfs-ctl --migrate --storagepoolid=2 --destinationpoolid=1 /mnt/beegfs/1G.file


gdb beegfs-ctl 
run --migrate --storagepoolid=2 --destinationpoolid=1 /mnt/beegfs/1G.file

break ModeMigrate.cpp:824
break ModeMigrate.cpp:938
break ModeMigrate::testFile



rpm -ivh beegfs-utils-7.3.2-el8.x86_64.rpm  libbeegfs-ib-7.3.2-el8.x86_64.rpm  beegfs-helperd-7.3.2-el8.x86_64.rpm

netstat -tan|awk '$1~/tcp/{print $NF}'|sort|uniq -c|sort -n

 md5sum  /usr/bin/beegfs-ctl
 
 
 
d8d0ddf72e06b8440fe45f7349cc501e  /usr/bin/beegfs-ctl

md5sum  /usr/bin/beegfs-ctl.temp
fa5a301585e21b8b6dbd2a2777f1e110  /usr/bin/beegfs-ctl.temp

md5sum  ./ctl/build/beegfs-ctl
fa5a301585e21b8b6dbd2a2777f1e110  ./ctl/build/beegfs-ctl



 beegfs-ctl
/usr/bin/beegfs-ctl

Helper daemon is unreachable => corresponding functionality (e.g. hostname resolution) currently unavailable


cat /proc/slabinfo |awk '{printf "%7i MiB : %s\n",$6*$(NF-1)/256,$1}'|sort -nk 1 -r|head -15


/opt/beegfs/sbin/beegfs-setup-client -m 188.188.12.40



/etc/init.d/beegfs-client rebuild


/etc/init.d/beegfs-client rebuild


/usr/lib/rpm/find-debuginfo.sh
为什么没有 debuginfo-xxx.rpm ？
+ cp beeond_thirdparty_gpl/build/COPYING /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/thirdparty/parallel/
+ /usr/lib/rpm/find-debuginfo.sh -j112 --strict-build-id -m -i --build-id-seed 7.3.2-el8 --unique-debug-suffix -7.3.2-el8.x86_64 --unique-debug-src-base beegfs-7.3.2-el8.x86_64 --run-dwz --dwz-low-mem-die-limit 10000000 --dwz-max-die-limit 110000000 -S debugsourcefiles.list /root/beegfs/packages11/BUILD/beegfs-7.3.2
extracting debug

/beegfs-7.3.2
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/lib/libbeegfs_ib.so
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-helperd
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-ctl
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/lib/libjbeegfs.so
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-meta
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-fsck
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-mgmtd
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-event-listener
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-mon
extracting debug info from /root/beegfs/packages11/BUILDROOT/beegfs-7.3.2-el8.x86_64/opt/beegfs/sbin/beegfs-storage





/diluv2/tools/vdbench50406/vdbench -f /diluv2/tools/vdbench50406/examples/filesys/create_files


perf record  -F 99  -g -a  -- sleep 20
perf record  -F 99  -g -e "kmem:*"  -- sleep 20
perf report --stdio
 
 

1. gdb 跟踪 beegfs内存增长问题
2. 总结之前处理方式




perf record -a -e kmem:kmalloc --filter 'bytes_alloc == 192' -e kmem:kfree --filter ' ptr != 0' sleep 200


for i in {1..1000};do  sleep 2 &&  cat /proc/slabinfo |grep task_struct |awk '{if($3*$4/1024/1024 > 100){print $1,$3*$4/1024/1024} }'  >> /root/local/perf/task_struct; done

cat /proc/slabinfo |grep task_struct |awk '{if($3*$4/1024/1024 > 100){print $1,$3*$4/1024/1024} }'  >> /root/local/perf/task_struct

cat /proc/slabinfo |awk '{if($3*$4/1024/1024 > 100){print $1,$3*$4/1024/1024} }'

Ctrl + 鼠标左击跳到定义.
返回：

Windows: Alt + ← ;或者 鼠标侧键
Linux: Ctrl + Alt + - ;貌似数字键盘的减号没效果
Mac: Ctrl + -

find /mnt/beegfs -type f |xargs -n1  -P 30  -I{} sh -c " echo {} && beegfs-ctl  --migrate   --storagepoolid=2 --destinationpoolid=1 {}"



115


[root@H36-6 ~]# free -g
              total        used        free      shared  buff/cache   available
Mem:            755          12         725           1          17         736
Swap:            62           0          62


21

[root@localhost ~]# free -g
              total        used        free      shared  buff/cache   available
Mem:           1007           7         997           0           2         995
Swap:            62           0          62


[root@localhost ~]# free -g
              total        used        free      shared  buff/cache   available
Mem:           1007          23         981           0           2         979
Swap:            62           0          62


[root@H36-6 ~]# free -g
              total        used        free      shared  buff/cache   available
Mem:            755          23         728           1           3         726
Swap:            62           0          62
